{"cells":[{"metadata":{},"cell_type":"markdown","source":"# IoT Intrusion Detection\n\nThe N-BaIoT Dataset contains traffic data for 9 IoT devices. The data comprise of both benign traffic and of a variety of malicious attacks. Here we run three deep neural networks to identify cyberattacks on a Provision PT-737E Security Camera."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"benign=pd.read_csv('../input/nbaiot-dataset/5.benign.csv')\ng_c=pd.read_csv('../input/nbaiot-dataset/5.gafgyt.combo.csv')\ng_j=pd.read_csv('../input/nbaiot-dataset/5.gafgyt.junk.csv')\ng_s=pd.read_csv('../input/nbaiot-dataset/5.gafgyt.scan.csv')\ng_t=pd.read_csv('../input/nbaiot-dataset/5.gafgyt.tcp.csv')\ng_u=pd.read_csv('../input/nbaiot-dataset/5.gafgyt.udp.csv')\nm_a=pd.read_csv('../input/nbaiot-dataset/5.mirai.ack.csv')\nm_sc=pd.read_csv('../input/nbaiot-dataset/5.mirai.scan.csv')\nm_sy=pd.read_csv('../input/nbaiot-dataset/5.mirai.syn.csv')\nm_u=pd.read_csv('../input/nbaiot-dataset/5.mirai.udp.csv')\nm_u_p=pd.read_csv('../input/nbaiot-dataset/5.mirai.udpplain.csv')\n\nbenign=benign.sample(frac=0.25,replace=False)\ng_c=g_c.sample(frac=0.25,replace=False)\ng_j=g_j.sample(frac=0.5,replace=False)\ng_s=g_s.sample(frac=0.5,replace=False)\ng_t=g_t.sample(frac=0.15,replace=False)\ng_u=g_u.sample(frac=0.15,replace=False)\nm_a=m_a.sample(frac=0.25,replace=False)\nm_sc=m_sc.sample(frac=0.15,replace=False)\nm_sy=m_sy.sample(frac=0.25,replace=False)\nm_u=m_u.sample(frac=0.1,replace=False)\nm_u_p=m_u_p.sample(frac=0.27,replace=False)\n\nbenign['type']='benign'\nm_u['type']='mirai_udp'\ng_c['type']='gafgyt_combo'\ng_j['type']='gafgyt_junk'\ng_s['type']='gafgyt_scan'\ng_t['type']='gafgyt_tcp'\ng_u['type']='gafgyt_udp'\nm_a['type']='mirai_ack'\nm_sc['type']='mirai_scan'\nm_sy['type']='mirai_syn'\nm_u_p['type']='mirai_udpplain'\n\ndata=pd.concat([benign,m_u,g_c,g_j,g_s,g_t,g_u,m_a,m_sc,m_sy,m_u_p],\n               axis=0, sort=False, ignore_index=True)","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#how many instances of each class\ndata.groupby('type')['type'].count()","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"type\nbenign            15538\ngafgyt_combo      15345\ngafgyt_junk       15449\ngafgyt_scan       14648\ngafgyt_tcp        15676\ngafgyt_udp        15602\nmirai_ack         15138\nmirai_scan        14517\nmirai_syn         16436\nmirai_udp         15625\nmirai_udpplain    15304\nName: type, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#shuffle rows of dataframe \nsampler=np.random.permutation(len(data))\ndata=data.take(sampler)\ndata.head()","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"        MI_dir_L5_weight  MI_dir_L5_mean  MI_dir_L5_variance  \\\n60031         178.995599       74.050143            1.200907   \n64001         101.851537       74.224578            1.895037   \n396             1.000000       89.999995            0.000142   \n160761        117.712393      241.659409        56738.482239   \n16788          72.610169      396.720117        52959.175999   \n\n        MI_dir_L3_weight  MI_dir_L3_mean  MI_dir_L3_variance  \\\n60031         290.819612       74.051090            1.223550   \n64001         145.156551       74.201216            2.085855   \n396             1.000083       89.997512            0.074627   \n160761        148.313014      268.062774        59487.822578   \n16788         132.006313      366.940755        57414.813814   \n\n        MI_dir_L1_weight  MI_dir_L1_mean  MI_dir_L1_variance  \\\n60031         842.045110       74.046596            1.300690   \n64001         235.881182       74.232467            4.439082   \n396             1.044969       88.725856           36.314277   \n160761        327.181582      298.674125        60918.005347   \n16788         385.989764      350.781922        59080.172651   \n\n        MI_dir_L0.1_weight  ...  HpHp_L0.1_covariance  HpHp_L0.1_pcc  \\\n60031          7133.068383  ...          0.000000e+00   0.000000e+00   \n64001          1145.050353  ...          0.000000e+00   0.000000e+00   \n396               3.859209  ...         -1.410000e-22  -8.190000e-14   \n160761         3168.853599  ...          0.000000e+00   0.000000e+00   \n16788          3912.156872  ...          0.000000e+00   0.000000e+00   \n\n        HpHp_L0.01_weight  HpHp_L0.01_mean  HpHp_L0.01_std  \\\n60031            1.000000        74.000000        0.000000   \n64001            2.898556        74.000000        0.000001   \n396              4.144635        88.766027        5.957895   \n160761           1.000000        60.000000        0.000000   \n16788            1.000000       554.000000        0.000000   \n\n        HpHp_L0.01_magnitude  HpHp_L0.01_radius  HpHp_L0.01_covariance  \\\n60031              74.000000       0.000000e+00               0.000000   \n64001              74.000000       1.818989e-12               0.000000   \n396               107.166871       3.549662e+01              -0.051091   \n160761             60.000000       0.000000e+00               0.000000   \n16788             554.000000       0.000000e+00               0.000000   \n\n        HpHp_L0.01_pcc            type  \n60031           0.0000     gafgyt_junk  \n64001           0.0000     gafgyt_scan  \n396            -0.0291          benign  \n160761          0.0000  mirai_udpplain  \n16788           0.0000       mirai_udp  \n\n[5 rows x 116 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MI_dir_L5_weight</th>\n      <th>MI_dir_L5_mean</th>\n      <th>MI_dir_L5_variance</th>\n      <th>MI_dir_L3_weight</th>\n      <th>MI_dir_L3_mean</th>\n      <th>MI_dir_L3_variance</th>\n      <th>MI_dir_L1_weight</th>\n      <th>MI_dir_L1_mean</th>\n      <th>MI_dir_L1_variance</th>\n      <th>MI_dir_L0.1_weight</th>\n      <th>...</th>\n      <th>HpHp_L0.1_covariance</th>\n      <th>HpHp_L0.1_pcc</th>\n      <th>HpHp_L0.01_weight</th>\n      <th>HpHp_L0.01_mean</th>\n      <th>HpHp_L0.01_std</th>\n      <th>HpHp_L0.01_magnitude</th>\n      <th>HpHp_L0.01_radius</th>\n      <th>HpHp_L0.01_covariance</th>\n      <th>HpHp_L0.01_pcc</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>60031</th>\n      <td>178.995599</td>\n      <td>74.050143</td>\n      <td>1.200907</td>\n      <td>290.819612</td>\n      <td>74.051090</td>\n      <td>1.223550</td>\n      <td>842.045110</td>\n      <td>74.046596</td>\n      <td>1.300690</td>\n      <td>7133.068383</td>\n      <td>...</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>1.000000</td>\n      <td>74.000000</td>\n      <td>0.000000</td>\n      <td>74.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.0000</td>\n      <td>gafgyt_junk</td>\n    </tr>\n    <tr>\n      <th>64001</th>\n      <td>101.851537</td>\n      <td>74.224578</td>\n      <td>1.895037</td>\n      <td>145.156551</td>\n      <td>74.201216</td>\n      <td>2.085855</td>\n      <td>235.881182</td>\n      <td>74.232467</td>\n      <td>4.439082</td>\n      <td>1145.050353</td>\n      <td>...</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>2.898556</td>\n      <td>74.000000</td>\n      <td>0.000001</td>\n      <td>74.000000</td>\n      <td>1.818989e-12</td>\n      <td>0.000000</td>\n      <td>0.0000</td>\n      <td>gafgyt_scan</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>1.000000</td>\n      <td>89.999995</td>\n      <td>0.000142</td>\n      <td>1.000083</td>\n      <td>89.997512</td>\n      <td>0.074627</td>\n      <td>1.044969</td>\n      <td>88.725856</td>\n      <td>36.314277</td>\n      <td>3.859209</td>\n      <td>...</td>\n      <td>-1.410000e-22</td>\n      <td>-8.190000e-14</td>\n      <td>4.144635</td>\n      <td>88.766027</td>\n      <td>5.957895</td>\n      <td>107.166871</td>\n      <td>3.549662e+01</td>\n      <td>-0.051091</td>\n      <td>-0.0291</td>\n      <td>benign</td>\n    </tr>\n    <tr>\n      <th>160761</th>\n      <td>117.712393</td>\n      <td>241.659409</td>\n      <td>56738.482239</td>\n      <td>148.313014</td>\n      <td>268.062774</td>\n      <td>59487.822578</td>\n      <td>327.181582</td>\n      <td>298.674125</td>\n      <td>60918.005347</td>\n      <td>3168.853599</td>\n      <td>...</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>1.000000</td>\n      <td>60.000000</td>\n      <td>0.000000</td>\n      <td>60.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.0000</td>\n      <td>mirai_udpplain</td>\n    </tr>\n    <tr>\n      <th>16788</th>\n      <td>72.610169</td>\n      <td>396.720117</td>\n      <td>52959.175999</td>\n      <td>132.006313</td>\n      <td>366.940755</td>\n      <td>57414.813814</td>\n      <td>385.989764</td>\n      <td>350.781922</td>\n      <td>59080.172651</td>\n      <td>3912.156872</td>\n      <td>...</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>1.000000</td>\n      <td>554.000000</td>\n      <td>0.000000</td>\n      <td>554.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.0000</td>\n      <td>mirai_udp</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 116 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dummy encode labels, store separately\nlabels_full=pd.get_dummies(data['type'], prefix='type')\nlabels_full.head()","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"        type_benign  type_gafgyt_combo  type_gafgyt_junk  type_gafgyt_scan  \\\n60031             0                  0                 1                 0   \n64001             0                  0                 0                 1   \n396               1                  0                 0                 0   \n160761            0                  0                 0                 0   \n16788             0                  0                 0                 0   \n\n        type_gafgyt_tcp  type_gafgyt_udp  type_mirai_ack  type_mirai_scan  \\\n60031                 0                0               0                0   \n64001                 0                0               0                0   \n396                   0                0               0                0   \n160761                0                0               0                0   \n16788                 0                0               0                0   \n\n        type_mirai_syn  type_mirai_udp  type_mirai_udpplain  \n60031                0               0                    0  \n64001                0               0                    0  \n396                  0               0                    0  \n160761               0               0                    1  \n16788                0               1                    0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type_benign</th>\n      <th>type_gafgyt_combo</th>\n      <th>type_gafgyt_junk</th>\n      <th>type_gafgyt_scan</th>\n      <th>type_gafgyt_tcp</th>\n      <th>type_gafgyt_udp</th>\n      <th>type_mirai_ack</th>\n      <th>type_mirai_scan</th>\n      <th>type_mirai_syn</th>\n      <th>type_mirai_udp</th>\n      <th>type_mirai_udpplain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>60031</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>64001</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>160761</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16788</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop labels from training dataset\ndata=data.drop(columns='type')\ndata.head()","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"        MI_dir_L5_weight  MI_dir_L5_mean  MI_dir_L5_variance  \\\n60031         178.995599       74.050143            1.200907   \n64001         101.851537       74.224578            1.895037   \n396             1.000000       89.999995            0.000142   \n160761        117.712393      241.659409        56738.482239   \n16788          72.610169      396.720117        52959.175999   \n\n        MI_dir_L3_weight  MI_dir_L3_mean  MI_dir_L3_variance  \\\n60031         290.819612       74.051090            1.223550   \n64001         145.156551       74.201216            2.085855   \n396             1.000083       89.997512            0.074627   \n160761        148.313014      268.062774        59487.822578   \n16788         132.006313      366.940755        57414.813814   \n\n        MI_dir_L1_weight  MI_dir_L1_mean  MI_dir_L1_variance  \\\n60031         842.045110       74.046596            1.300690   \n64001         235.881182       74.232467            4.439082   \n396             1.044969       88.725856           36.314277   \n160761        327.181582      298.674125        60918.005347   \n16788         385.989764      350.781922        59080.172651   \n\n        MI_dir_L0.1_weight  ...  HpHp_L0.1_radius  HpHp_L0.1_covariance  \\\n60031          7133.068383  ...      0.000000e+00          0.000000e+00   \n64001          1145.050353  ...      9.094947e-13          0.000000e+00   \n396               3.859209  ...      6.550000e-06         -1.410000e-22   \n160761         3168.853599  ...      0.000000e+00          0.000000e+00   \n16788          3912.156872  ...      0.000000e+00          0.000000e+00   \n\n        HpHp_L0.1_pcc  HpHp_L0.01_weight  HpHp_L0.01_mean  HpHp_L0.01_std  \\\n60031    0.000000e+00           1.000000        74.000000        0.000000   \n64001    0.000000e+00           2.898556        74.000000        0.000001   \n396     -8.190000e-14           4.144635        88.766027        5.957895   \n160761   0.000000e+00           1.000000        60.000000        0.000000   \n16788    0.000000e+00           1.000000       554.000000        0.000000   \n\n        HpHp_L0.01_magnitude  HpHp_L0.01_radius  HpHp_L0.01_covariance  \\\n60031              74.000000       0.000000e+00               0.000000   \n64001              74.000000       1.818989e-12               0.000000   \n396               107.166871       3.549662e+01              -0.051091   \n160761             60.000000       0.000000e+00               0.000000   \n16788             554.000000       0.000000e+00               0.000000   \n\n        HpHp_L0.01_pcc  \n60031           0.0000  \n64001           0.0000  \n396            -0.0291  \n160761          0.0000  \n16788           0.0000  \n\n[5 rows x 115 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MI_dir_L5_weight</th>\n      <th>MI_dir_L5_mean</th>\n      <th>MI_dir_L5_variance</th>\n      <th>MI_dir_L3_weight</th>\n      <th>MI_dir_L3_mean</th>\n      <th>MI_dir_L3_variance</th>\n      <th>MI_dir_L1_weight</th>\n      <th>MI_dir_L1_mean</th>\n      <th>MI_dir_L1_variance</th>\n      <th>MI_dir_L0.1_weight</th>\n      <th>...</th>\n      <th>HpHp_L0.1_radius</th>\n      <th>HpHp_L0.1_covariance</th>\n      <th>HpHp_L0.1_pcc</th>\n      <th>HpHp_L0.01_weight</th>\n      <th>HpHp_L0.01_mean</th>\n      <th>HpHp_L0.01_std</th>\n      <th>HpHp_L0.01_magnitude</th>\n      <th>HpHp_L0.01_radius</th>\n      <th>HpHp_L0.01_covariance</th>\n      <th>HpHp_L0.01_pcc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>60031</th>\n      <td>178.995599</td>\n      <td>74.050143</td>\n      <td>1.200907</td>\n      <td>290.819612</td>\n      <td>74.051090</td>\n      <td>1.223550</td>\n      <td>842.045110</td>\n      <td>74.046596</td>\n      <td>1.300690</td>\n      <td>7133.068383</td>\n      <td>...</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>1.000000</td>\n      <td>74.000000</td>\n      <td>0.000000</td>\n      <td>74.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>64001</th>\n      <td>101.851537</td>\n      <td>74.224578</td>\n      <td>1.895037</td>\n      <td>145.156551</td>\n      <td>74.201216</td>\n      <td>2.085855</td>\n      <td>235.881182</td>\n      <td>74.232467</td>\n      <td>4.439082</td>\n      <td>1145.050353</td>\n      <td>...</td>\n      <td>9.094947e-13</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>2.898556</td>\n      <td>74.000000</td>\n      <td>0.000001</td>\n      <td>74.000000</td>\n      <td>1.818989e-12</td>\n      <td>0.000000</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>1.000000</td>\n      <td>89.999995</td>\n      <td>0.000142</td>\n      <td>1.000083</td>\n      <td>89.997512</td>\n      <td>0.074627</td>\n      <td>1.044969</td>\n      <td>88.725856</td>\n      <td>36.314277</td>\n      <td>3.859209</td>\n      <td>...</td>\n      <td>6.550000e-06</td>\n      <td>-1.410000e-22</td>\n      <td>-8.190000e-14</td>\n      <td>4.144635</td>\n      <td>88.766027</td>\n      <td>5.957895</td>\n      <td>107.166871</td>\n      <td>3.549662e+01</td>\n      <td>-0.051091</td>\n      <td>-0.0291</td>\n    </tr>\n    <tr>\n      <th>160761</th>\n      <td>117.712393</td>\n      <td>241.659409</td>\n      <td>56738.482239</td>\n      <td>148.313014</td>\n      <td>268.062774</td>\n      <td>59487.822578</td>\n      <td>327.181582</td>\n      <td>298.674125</td>\n      <td>60918.005347</td>\n      <td>3168.853599</td>\n      <td>...</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>1.000000</td>\n      <td>60.000000</td>\n      <td>0.000000</td>\n      <td>60.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>16788</th>\n      <td>72.610169</td>\n      <td>396.720117</td>\n      <td>52959.175999</td>\n      <td>132.006313</td>\n      <td>366.940755</td>\n      <td>57414.813814</td>\n      <td>385.989764</td>\n      <td>350.781922</td>\n      <td>59080.172651</td>\n      <td>3912.156872</td>\n      <td>...</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>1.000000</td>\n      <td>554.000000</td>\n      <td>0.000000</td>\n      <td>554.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.0000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 115 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#standardize numerical columns\ndef standardize(df,col):\n    df[col]= (df[col]-df[col].mean())/df[col].std()\n\ndata_st=data.copy()\nfor i in (data_st.iloc[:,:-1].columns):\n    standardize (data_st,i)\n\ndata_st.head()","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"        MI_dir_L5_weight  MI_dir_L5_mean  MI_dir_L5_variance  \\\n60031           1.599450       -0.507971           -0.604957   \n64001           0.407907       -0.506628           -0.604927   \n396            -1.149815       -0.385175           -0.605008   \n160761          0.652889        0.782431            1.818220   \n16788          -0.043747        1.976223            1.656811   \n\n        MI_dir_L3_weight  MI_dir_L3_mean  MI_dir_L3_variance  \\\n60031           1.712892       -0.532790           -0.626508   \n64001           0.280967       -0.531579           -0.626474   \n396            -1.136147       -0.404194           -0.626554   \n160761          0.311997        1.031775            1.750574   \n16788           0.151695        1.829155            1.667737   \n\n        MI_dir_L1_weight  MI_dir_L1_mean  MI_dir_L1_variance  \\\n60031           1.874677       -0.561921           -0.643784   \n64001          -0.282697       -0.560348           -0.643667   \n396            -1.118493       -0.437698           -0.642472   \n160761          0.042247        1.338988            1.639342   \n16788           0.251548        1.779950            1.570461   \n\n        MI_dir_L0.1_weight  ...  HpHp_L0.1_radius  HpHp_L0.1_covariance  \\\n60031             1.894803  ...         -0.100527             -0.098394   \n64001            -0.651224  ...         -0.100527             -0.098394   \n396              -1.136444  ...         -0.100527             -0.098394   \n160761            0.209271  ...         -0.100527             -0.098394   \n16788             0.525314  ...         -0.100527             -0.098394   \n\n        HpHp_L0.1_pcc  HpHp_L0.01_weight  HpHp_L0.01_mean  HpHp_L0.01_std  \\\n60031         -0.0714          -0.199100        -0.384781       -0.129166   \n64001         -0.0714          -0.198116        -0.384781       -0.129166   \n396           -0.0714          -0.197469        -0.300168        0.061202   \n160761        -0.0714          -0.199100        -0.465006       -0.129166   \n16788         -0.0714          -0.199100         2.365759       -0.129166   \n\n        HpHp_L0.01_magnitude  HpHp_L0.01_radius  HpHp_L0.01_covariance  \\\n60031              -0.406459          -0.099967              -0.095797   \n64001              -0.406459          -0.099967              -0.095797   \n396                -0.218981          -0.097936              -0.095812   \n160761             -0.485594          -0.099967              -0.095797   \n16788               2.306766          -0.099967              -0.095797   \n\n        HpHp_L0.01_pcc  \n60031           0.0000  \n64001           0.0000  \n396            -0.0291  \n160761          0.0000  \n16788           0.0000  \n\n[5 rows x 115 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MI_dir_L5_weight</th>\n      <th>MI_dir_L5_mean</th>\n      <th>MI_dir_L5_variance</th>\n      <th>MI_dir_L3_weight</th>\n      <th>MI_dir_L3_mean</th>\n      <th>MI_dir_L3_variance</th>\n      <th>MI_dir_L1_weight</th>\n      <th>MI_dir_L1_mean</th>\n      <th>MI_dir_L1_variance</th>\n      <th>MI_dir_L0.1_weight</th>\n      <th>...</th>\n      <th>HpHp_L0.1_radius</th>\n      <th>HpHp_L0.1_covariance</th>\n      <th>HpHp_L0.1_pcc</th>\n      <th>HpHp_L0.01_weight</th>\n      <th>HpHp_L0.01_mean</th>\n      <th>HpHp_L0.01_std</th>\n      <th>HpHp_L0.01_magnitude</th>\n      <th>HpHp_L0.01_radius</th>\n      <th>HpHp_L0.01_covariance</th>\n      <th>HpHp_L0.01_pcc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>60031</th>\n      <td>1.599450</td>\n      <td>-0.507971</td>\n      <td>-0.604957</td>\n      <td>1.712892</td>\n      <td>-0.532790</td>\n      <td>-0.626508</td>\n      <td>1.874677</td>\n      <td>-0.561921</td>\n      <td>-0.643784</td>\n      <td>1.894803</td>\n      <td>...</td>\n      <td>-0.100527</td>\n      <td>-0.098394</td>\n      <td>-0.0714</td>\n      <td>-0.199100</td>\n      <td>-0.384781</td>\n      <td>-0.129166</td>\n      <td>-0.406459</td>\n      <td>-0.099967</td>\n      <td>-0.095797</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>64001</th>\n      <td>0.407907</td>\n      <td>-0.506628</td>\n      <td>-0.604927</td>\n      <td>0.280967</td>\n      <td>-0.531579</td>\n      <td>-0.626474</td>\n      <td>-0.282697</td>\n      <td>-0.560348</td>\n      <td>-0.643667</td>\n      <td>-0.651224</td>\n      <td>...</td>\n      <td>-0.100527</td>\n      <td>-0.098394</td>\n      <td>-0.0714</td>\n      <td>-0.198116</td>\n      <td>-0.384781</td>\n      <td>-0.129166</td>\n      <td>-0.406459</td>\n      <td>-0.099967</td>\n      <td>-0.095797</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>-1.149815</td>\n      <td>-0.385175</td>\n      <td>-0.605008</td>\n      <td>-1.136147</td>\n      <td>-0.404194</td>\n      <td>-0.626554</td>\n      <td>-1.118493</td>\n      <td>-0.437698</td>\n      <td>-0.642472</td>\n      <td>-1.136444</td>\n      <td>...</td>\n      <td>-0.100527</td>\n      <td>-0.098394</td>\n      <td>-0.0714</td>\n      <td>-0.197469</td>\n      <td>-0.300168</td>\n      <td>0.061202</td>\n      <td>-0.218981</td>\n      <td>-0.097936</td>\n      <td>-0.095812</td>\n      <td>-0.0291</td>\n    </tr>\n    <tr>\n      <th>160761</th>\n      <td>0.652889</td>\n      <td>0.782431</td>\n      <td>1.818220</td>\n      <td>0.311997</td>\n      <td>1.031775</td>\n      <td>1.750574</td>\n      <td>0.042247</td>\n      <td>1.338988</td>\n      <td>1.639342</td>\n      <td>0.209271</td>\n      <td>...</td>\n      <td>-0.100527</td>\n      <td>-0.098394</td>\n      <td>-0.0714</td>\n      <td>-0.199100</td>\n      <td>-0.465006</td>\n      <td>-0.129166</td>\n      <td>-0.485594</td>\n      <td>-0.099967</td>\n      <td>-0.095797</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>16788</th>\n      <td>-0.043747</td>\n      <td>1.976223</td>\n      <td>1.656811</td>\n      <td>0.151695</td>\n      <td>1.829155</td>\n      <td>1.667737</td>\n      <td>0.251548</td>\n      <td>1.779950</td>\n      <td>1.570461</td>\n      <td>0.525314</td>\n      <td>...</td>\n      <td>-0.100527</td>\n      <td>-0.098394</td>\n      <td>-0.0714</td>\n      <td>-0.199100</td>\n      <td>2.365759</td>\n      <td>-0.129166</td>\n      <td>2.306766</td>\n      <td>-0.099967</td>\n      <td>-0.095797</td>\n      <td>0.0000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 115 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#training data for the neural net\ntrain_data_st=data_st.values\ntrain_data_st","execution_count":33,"outputs":[{"output_type":"execute_result","execution_count":33,"data":{"text/plain":"array([[ 1.59945016, -0.50797071, -0.60495687, ..., -0.09996714,\n        -0.09579688,  0.        ],\n       [ 0.40790665, -0.50662775, -0.60492723, ..., -0.09996714,\n        -0.09579688,  0.        ],\n       [-1.14981525, -0.38517491, -0.60500815, ..., -0.09793573,\n        -0.09581209, -0.02910016],\n       ...,\n       [ 1.60525428,  0.9524347 ,  2.02359887, ..., -0.09996714,\n        -0.09579688,  0.        ],\n       [-1.14981525, -0.61614089, -0.60500816, ..., -0.09996714,\n        -0.09579688,  0.        ],\n       [-0.9177174 ,  0.26633739,  1.59479183, ...,  4.30946084,\n         6.58235836,  0.41975018]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#labels for training\nlabels=labels_full.values\nlabels","execution_count":34,"outputs":[{"output_type":"execute_result","execution_count":34,"data":{"text/plain":"array([[0, 0, 1, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [1, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [1, 0, 0, ..., 0, 0, 0]], dtype=uint8)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Keras model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#import libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n\n# test/train split  25% test\nx_train_st, x_test_st, y_train_st, y_test_st = train_test_split(\n    train_data_st, labels, test_size=0.25, random_state=42)\n\n#  create and fit model\nmodel = Sequential()\nmodel.add(Dense(10, input_dim=train_data_st.shape[1], activation='relu'))\nmodel.add(Dense(40, input_dim=train_data_st.shape[1], activation='relu'))\nmodel.add(Dense(10, input_dim=train_data_st.shape[1], activation='relu'))\nmodel.add(Dense(1, kernel_initializer='normal'))\nmodel.add(Dense(labels.shape[1],activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam')\nmonitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n                        patience=5, verbose=1, mode='auto')\nmodel.fit(x_train_st,y_train_st,validation_data=(x_test_st,y_test_st),\n          callbacks=[monitor],verbose=2,epochs=500)","execution_count":35,"outputs":[{"output_type":"stream","text":"Epoch 1/500\n3968/3968 - 6s - loss: 1.2674 - val_loss: 0.9334\nEpoch 2/500\n3968/3968 - 5s - loss: 0.7948 - val_loss: 0.7126\nEpoch 3/500\n3968/3968 - 5s - loss: 0.6303 - val_loss: 0.5619\nEpoch 4/500\n3968/3968 - 5s - loss: 0.5403 - val_loss: 0.4992\nEpoch 5/500\n3968/3968 - 5s - loss: 0.4787 - val_loss: 0.4690\nEpoch 6/500\n3968/3968 - 6s - loss: 0.4314 - val_loss: 0.4915\nEpoch 7/500\n3968/3968 - 5s - loss: 0.4025 - val_loss: 0.4030\nEpoch 8/500\n3968/3968 - 5s - loss: 0.3806 - val_loss: 0.4125\nEpoch 9/500\n3968/3968 - 5s - loss: 0.3598 - val_loss: 0.3538\nEpoch 10/500\n3968/3968 - 5s - loss: 0.3487 - val_loss: 0.4265\nEpoch 11/500\n3968/3968 - 5s - loss: 0.3412 - val_loss: 0.3331\nEpoch 12/500\n3968/3968 - 5s - loss: 0.3322 - val_loss: 0.3347\nEpoch 13/500\n3968/3968 - 5s - loss: 0.3227 - val_loss: 0.3229\nEpoch 14/500\n3968/3968 - 5s - loss: 0.3154 - val_loss: 0.3312\nEpoch 15/500\n3968/3968 - 6s - loss: 0.3102 - val_loss: 0.3388\nEpoch 16/500\n3968/3968 - 6s - loss: 0.3017 - val_loss: 0.3154\nEpoch 17/500\n3968/3968 - 5s - loss: 0.2998 - val_loss: 0.3037\nEpoch 18/500\n3968/3968 - 5s - loss: 0.2931 - val_loss: 0.3228\nEpoch 19/500\n3968/3968 - 5s - loss: 0.2880 - val_loss: 0.3135\nEpoch 20/500\n3968/3968 - 5s - loss: 0.2828 - val_loss: 0.2945\nEpoch 21/500\n3968/3968 - 5s - loss: 0.2797 - val_loss: 0.3344\nEpoch 22/500\n3968/3968 - 5s - loss: 0.2750 - val_loss: 0.2919\nEpoch 23/500\n3968/3968 - 5s - loss: 0.2712 - val_loss: 0.3067\nEpoch 24/500\n3968/3968 - 5s - loss: 0.2666 - val_loss: 0.2870\nEpoch 25/500\n3968/3968 - 5s - loss: 0.2658 - val_loss: 0.2976\nEpoch 26/500\n3968/3968 - 5s - loss: 0.2563 - val_loss: 0.2784\nEpoch 27/500\n3968/3968 - 5s - loss: 0.2519 - val_loss: 0.3210\nEpoch 28/500\n3968/3968 - 5s - loss: 0.2451 - val_loss: 0.2719\nEpoch 29/500\n3968/3968 - 5s - loss: 0.2353 - val_loss: 0.2586\nEpoch 30/500\n3968/3968 - 5s - loss: 0.2303 - val_loss: 0.2736\nEpoch 31/500\n3968/3968 - 5s - loss: 0.2255 - val_loss: 0.2531\nEpoch 32/500\n3968/3968 - 5s - loss: 0.2179 - val_loss: 0.2475\nEpoch 33/500\n3968/3968 - 5s - loss: 0.2140 - val_loss: 0.2416\nEpoch 34/500\n3968/3968 - 5s - loss: 0.2109 - val_loss: 0.2390\nEpoch 35/500\n3968/3968 - 5s - loss: 0.2085 - val_loss: 0.2520\nEpoch 36/500\n3968/3968 - 5s - loss: 0.2046 - val_loss: 0.2325\nEpoch 37/500\n3968/3968 - 5s - loss: 0.2048 - val_loss: 0.2538\nEpoch 38/500\n3968/3968 - 5s - loss: 0.2025 - val_loss: 0.2533\nEpoch 39/500\n3968/3968 - 5s - loss: 0.2004 - val_loss: 0.2342\nEpoch 40/500\n3968/3968 - 5s - loss: 0.1996 - val_loss: 0.2609\nEpoch 41/500\n3968/3968 - 5s - loss: 0.1934 - val_loss: 0.2683\nEpoch 00041: early stopping\n","name":"stdout"},{"output_type":"execute_result","execution_count":35,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7fe9581cba50>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# metrics\npred_st = model.predict(x_test_st)\npred_st = np.argmax(pred_st,axis=1)\ny_eval_st = np.argmax(y_test_st,axis=1)\nscore_st = metrics.accuracy_score(y_eval_st, pred_st)\nprint(\"accuracy: {}\".format(score_st))","execution_count":36,"outputs":[{"output_type":"stream","text":"accuracy: 0.9005907372400757\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#second model\nmodel2 = Sequential()\nmodel2.add(Dense(32, input_dim=train_data_st.shape[1], activation='relu'))\nmodel2.add(Dense(72, input_dim=train_data_st.shape[1], activation='relu'))\nmodel2.add(Dense(32, input_dim=train_data_st.shape[1], activation='relu'))\nmodel2.add(Dense(1, kernel_initializer='normal'))\nmodel2.add(Dense(labels.shape[1],activation='softmax'))\nmodel2.compile(loss='categorical_crossentropy', optimizer='adam')\nmonitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n                        patience=5, verbose=1, mode='auto')\nmodel2.fit(x_train_st,y_train_st,validation_data=(x_test_st,y_test_st),\n          callbacks=[monitor],verbose=2,epochs=100)","execution_count":39,"outputs":[{"output_type":"stream","text":"Epoch 1/100\n3968/3968 - 6s - loss: 1.1276 - val_loss: 0.8256\nEpoch 2/100\n3968/3968 - 6s - loss: 0.7210 - val_loss: 0.6107\nEpoch 3/100\n3968/3968 - 6s - loss: 0.5550 - val_loss: 0.4708\nEpoch 4/100\n3968/3968 - 5s - loss: 0.4604 - val_loss: 0.4115\nEpoch 5/100\n3968/3968 - 6s - loss: 0.3906 - val_loss: 0.3522\nEpoch 6/100\n3968/3968 - 6s - loss: 0.3606 - val_loss: 0.3247\nEpoch 7/100\n3968/3968 - 6s - loss: 0.3429 - val_loss: 0.3278\nEpoch 8/100\n3968/3968 - 6s - loss: 0.3107 - val_loss: 0.2856\nEpoch 9/100\n3968/3968 - 6s - loss: 0.2837 - val_loss: 0.2830\nEpoch 10/100\n3968/3968 - 6s - loss: 0.2680 - val_loss: 0.2414\nEpoch 11/100\n3968/3968 - 6s - loss: 0.2535 - val_loss: 0.2352\nEpoch 12/100\n3968/3968 - 6s - loss: 0.2162 - val_loss: 0.2018\nEpoch 13/100\n3968/3968 - 6s - loss: 0.2297 - val_loss: 0.2170\nEpoch 14/100\n3968/3968 - 6s - loss: 0.2098 - val_loss: 0.3826\nEpoch 15/100\n3968/3968 - 6s - loss: 0.1917 - val_loss: 0.2199\nEpoch 16/100\n3968/3968 - 6s - loss: 0.2061 - val_loss: 0.3002\nEpoch 17/100\n3968/3968 - 6s - loss: 0.1894 - val_loss: 0.1749\nEpoch 18/100\n3968/3968 - 6s - loss: 0.1916 - val_loss: 0.1805\nEpoch 19/100\n3968/3968 - 6s - loss: 0.1847 - val_loss: 0.1929\nEpoch 20/100\n3968/3968 - 6s - loss: 0.1842 - val_loss: 0.1757\nEpoch 21/100\n3968/3968 - 6s - loss: 0.1846 - val_loss: 0.1652\nEpoch 22/100\n3968/3968 - 6s - loss: 0.1929 - val_loss: 0.1939\nEpoch 23/100\n3968/3968 - 6s - loss: 0.1806 - val_loss: 0.1810\nEpoch 24/100\n3968/3968 - 6s - loss: 0.1785 - val_loss: 0.1711\nEpoch 25/100\n3968/3968 - 6s - loss: 0.1753 - val_loss: 0.1791\nEpoch 26/100\n3968/3968 - 6s - loss: 0.1754 - val_loss: 0.2000\nEpoch 00026: early stopping\n","name":"stdout"},{"output_type":"execute_result","execution_count":39,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7fe95a786310>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# metrics\npred_st = model2.predict(x_test_st)\npred_st = np.argmax(pred_st,axis=1)\ny_eval_st = np.argmax(y_test_st,axis=1)\nscore_st = metrics.accuracy_score(y_eval_st, pred_st)\nprint(\"accuracy: {}\".format(score_st))","execution_count":40,"outputs":[{"output_type":"stream","text":"accuracy: 0.8926748582230624\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}